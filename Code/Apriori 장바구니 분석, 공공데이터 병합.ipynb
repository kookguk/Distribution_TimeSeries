{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d570b8b6",
   "metadata": {},
   "source": [
    "# 1. '라면,통조림,상옥즉석' 중분류에 대한 장바구니 분석\n",
    "- 이거는 일단 해본거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d8b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# 장바구니 분석을 수행하는 함수\n",
    "def basket_analysis(data):\n",
    "    unique_dates = data['판매일'].unique()\n",
    "    final_results = pd.DataFrame()\n",
    "\n",
    "    for sale_date in unique_dates:\n",
    "        # 판매일 별로 데이터 필터링\n",
    "        date_data = data[data['판매일'] == sale_date]\n",
    "\n",
    "        # 대분류가 '면류.라면류'인 항목만 필터링\n",
    "        date_data = date_data[date_data['대분류'] == '면류.라면류']\n",
    "\n",
    "        # 매출처코드별로 대분류를 one-hot encoding하여 장바구니 행렬 생성\n",
    "        basket = (date_data\n",
    "                  .groupby(['매출처코드', '대분류'])['판매일']\n",
    "                  .count()\n",
    "                  .unstack()\n",
    "                  .reset_index()\n",
    "                  .fillna(0)\n",
    "                  .set_index('매출처코드'))\n",
    "\n",
    "        # 1과 0으로 이진화\n",
    "        basket_sets = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        # Apriori 알고리즘을 사용하여 빈번한 아이템 집합 찾기 (지지도 최소값 0.01)\n",
    "        frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True)\n",
    "\n",
    "        # 연관 규칙 생성\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "        # Antecedents에 '라면, 통조림, 상온즉석'이 포함된 규칙만 필터링\n",
    "        rules_filtered = rules[rules['antecedents'].apply(lambda x: '면류.라면류' in x)]\n",
    "\n",
    "        # 판매일자를 추가하여 결과 저장\n",
    "        if not rules_filtered.empty:\n",
    "            rules_filtered = rules_filtered.copy()\n",
    "            rules_filtered['판매일'] = sale_date  # 판매일 추가\n",
    "            final_results = pd.concat([final_results, rules_filtered], axis=0)\n",
    "\n",
    "    # '판매일' 컬럼을 맨 앞으로 이동\n",
    "    if '판매일' in final_results.columns:\n",
    "        final_results = final_results[['판매일'] + [col for col in final_results.columns if col != '판매일']]\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe94a16",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '(2데이터)옵션코드별 이상치 처리 병합_주 단위(3).xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 실제 실행 코드\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 데이터를 업로드하시면 해당 데이터를 data 변수로 활용하세요.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(2데이터)옵션코드별 이상치 처리 병합_주 단위(3).xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 업로드한 파일 경로 사용\u001b[39;00m\n\u001b[1;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m basket_analysis(data)\n\u001b[1;32m      6\u001b[0m save_results(results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m면류,라면류 장바구니 분석 결과.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    552\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/excel/_base.py:563\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[1;32m    560\u001b[0m     handle\u001b[38;5;241m=\u001b[39mfilepath_or_buffer, compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class)):\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class):\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '(2데이터)옵션코드별 이상치 처리 병합_주 단위(3).xlsx'"
     ]
    }
   ],
   "source": [
    "# 실제 실행 코드\n",
    "# 데이터를 업로드하시면 해당 데이터를 data 변수로 활용하세요.\n",
    "data = pd.read_excel('(2데이터)옵션코드별 이상치 처리 병합_주 단위(3).xlsx', engine='openpyxl')  # 업로드한 파일 경로 사용\n",
    "\n",
    "results = basket_analysis(data)\n",
    "save_results(results, '면류,라면류 장바구니 분석 결과.csv')\n",
    "print(\"CSV 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ddd69",
   "metadata": {},
   "source": [
    "# 2. 전체 중분류 장바구니 분석 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# 장바구니 분석을 수행하는 함수\n",
    "def basket_analysis(data):\n",
    "    unique_dates = data['판매일'].unique()\n",
    "    final_results = pd.DataFrame()\n",
    "\n",
    "    for sale_date in unique_dates:\n",
    "        # 판매일 별로 데이터 필터링\n",
    "        date_data = data[data['판매일'] == sale_date]\n",
    "        \n",
    "        # 매출처코드별로 중분류를 one-hot encoding하여 장바구니 행렬 생성\n",
    "        basket = (date_data\n",
    "                  .groupby(['매출처코드', '대분류'])['판매일']\n",
    "                  .count()\n",
    "                  .unstack()\n",
    "                  .reset_index()\n",
    "                  .fillna(0)\n",
    "                  .set_index('매출처코드'))\n",
    "\n",
    "        # 1과 0으로 이진화\n",
    "        basket_sets = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        # Apriori 알고리즘을 사용하여 빈번한 아이템 집합 찾기 (지지도 최소값 0.01)\n",
    "        frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True)\n",
    "\n",
    "        # 연관 규칙 생성\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "        # 판매일자를 추가하여 결과 저장\n",
    "        if not rules.empty:\n",
    "            rules = rules.copy()\n",
    "            rules['판매일'] = sale_date  # 판매일 추가\n",
    "            final_results = pd.concat([final_results, rules], axis=0)\n",
    "\n",
    "    # '판매일' 컬럼을 맨 앞으로 이동\n",
    "    if '판매일' in final_results.columns:\n",
    "        final_results = final_results[['판매일'] + [col for col in final_results.columns if col != '판매일']]\n",
    "\n",
    "    return final_results\n",
    "\n",
    "# CSV로 결과 저장\n",
    "def save_results(results, output_file):\n",
    "    results.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 실행 코드\n",
    "data = pd.read_excel('(2데이터)옵션코드별 이상치 처리 병합_주 단위.xlsx')  # 업로드한 파일 경로 사용\n",
    "\n",
    "results = basket_analysis(data)\n",
    "save_results(results, '전체 대분류 장바구니 분석 결과.csv')\n",
    "print(\"CSV 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651f777",
   "metadata": {},
   "source": [
    "## 2.1 판매일자별 antecedents의 중분류1개, consequents의 중분류1개 인 행만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv('전체 대분류 장바구니 분석 결과.csv',encoding='utf-8')\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f09c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antecedents와 consequents 각각의 길이가 1인 경우만 남기기\n",
    "filtered_total = total[total['antecedents'].apply(lambda x: len(eval(x)) == 1) & total['consequents'].apply(lambda x: len(eval(x)) == 1)]\n",
    "filtered_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total = filtered_total.reset_index(drop=True)\n",
    "filtered_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20개\n",
    "filtered_total['antecedents'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15개\n",
    "filtered_total['consequents'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6017a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total[filtered_total['판매일']=='2021-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozenset을 없애고 안의 값만 추출하는 함수\n",
    "def extract_values(frozenset_str):\n",
    "    # eval()로 frozenset을 리스트로 변환한 후, 첫 번째 값을 문자열로 변환\n",
    "    return ', '.join(list(eval(frozenset_str)))\n",
    "\n",
    "# antecedents와 consequents에서 frozenset과 '' 제거\n",
    "filtered_total['antecedents'] = filtered_total['antecedents'].apply(extract_values)\n",
    "filtered_total['consequents'] = filtered_total['consequents'].apply(extract_values)\n",
    "\n",
    "# # 원하는 컬럼만 남기기\n",
    "# filtered_total = filtered_total[['판매일', 'antecedents', 'consequents', 'confidence']]\n",
    "# filtered_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063007d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일로 저장 (필요시)\n",
    "filtered_total.to_csv('1대1 대응 장바구니 분석 결과.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887b3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ac41ec",
   "metadata": {},
   "source": [
    "# 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "week = pd.read_excel('(2데이터)옵션코드별 이상치 처리 병합_주 단위.xlsx')  # 업로드한 파일 경로 사용\n",
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a36a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "week['대분류'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "week['중분류'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '중분류' 값을 기준으로 더미 컬럼 생성\n",
    "week_dummies = pd.get_dummies(week['대분류'])\n",
    "\n",
    "# 기존 week 데이터프레임에 더미 컬럼 추가\n",
    "week_with_dummies = pd.concat([week, week_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77031fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '1대1 대응 장바구니 분석 결과.csv'와 'week_with_dummies' 파일 불러오기\n",
    "basket_analysis_result = pd.read_csv('1대1 대응 장바구니 분석 결과.csv')\n",
    "\n",
    "# 각 행에 대해 조건을 만족하는 경우 confidence 값을 채워넣기\n",
    "for _, row in basket_analysis_result.iterrows():\n",
    "    # 판매일, antecedents, consequents, confidence 값 추출\n",
    "    sale_date = row['판매일']\n",
    "    antecedent = row['antecedents']  # 이미 문자열이므로 그대로 사용\n",
    "    consequent = row['consequents']  # 이미 문자열이므로 그대로 사용\n",
    "    confidence_value = row['confidence']\n",
    "    \n",
    "    # 해당 조건을 만족하는 행 찾기 (판매일과 중분류가 일치하는 경우)\n",
    "    condition = (week_with_dummies['판매일'] == sale_date) & (week_with_dummies['대분류'] == antecedent)\n",
    "    \n",
    "    # 해당하는 셀에 confidence 값을 삽입\n",
    "    week_with_dummies.loc[condition, consequent] = confidence_value\n",
    "\n",
    "# 이제 남아있는 값들에 대해 False -> 0, True -> 1 변환\n",
    "# 중분류 값에서 파생된 22개의 열들만 변환\n",
    "subcategories_columns = week_with_dummies.columns[week_with_dummies.columns.isin(basket_analysis_result['consequents'])]\n",
    "\n",
    "# 해당 컬럼들에 대해 남은 값들을 변환 (False -> 0, True -> 1)\n",
    "week_with_dummies[subcategories_columns] = week_with_dummies[subcategories_columns].applymap(lambda x: 1 if x == True else (0 if x == False else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6520c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인 후 저장\n",
    "week_with_dummies.to_excel('주차별 장바구니 분석 결과 병합.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb62f0",
   "metadata": {},
   "source": [
    "# 3. 공공데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bce754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggdata = pd.read_excel('공공데이터.xlsx')\n",
    "ggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f58315",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggdata['연월'] = ggdata['연월'].astype('str')\n",
    "ggdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12222c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 연도의 '1'을 '10'으로 변경하는 코드\n",
    "def custom_change(x):\n",
    "    year, month = x.split('.')\n",
    "    if month == '1' and year in ['2021', '2022', '2023']:\n",
    "        return f'{year}.10'\n",
    "    else:\n",
    "        return f'{year}.{month.zfill(2)}'\n",
    "\n",
    "# 연월 컬럼에 적용\n",
    "ggdata['연월'] = ggdata['연월'].apply(custom_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3257990",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장바구니 결과 불러오기\n",
    "import pandas as pd\n",
    "com = pd.read_excel('주차별 장바구니 분석 결과 병합.xlsx')\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연월 컬럼 만들기\n",
    "com['연월'] = com['판매일'].dt.strftime('%Y.%m')\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조인\n",
    "merged_data = pd.merge(com, ggdata, on='연월', how='left')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a2805",
   "metadata": {},
   "source": [
    "# 4. 평균 발주일자 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d17dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = pd.read_excel('매출처코드별 평균발주일자 및 총발주건수.xlsx')\n",
    "ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_total = pd.merge(merged_data, ord, on='매출처코드', how='left')\n",
    "merged_data_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77943974",
   "metadata": {},
   "source": [
    "# 5. 중분류가 '라면,통조림,상온즉석'인 행만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = merged_data_total[merged_data_total['대분류']=='면류.라면류'].reset_index(drop=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연월 컬럼 제거\n",
    "data1 = data1.drop('연월', axis=1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ca03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('데이터2 라면,통조림,상온즉석 통합.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc8689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
